{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**EXAMPLE**\n",
        "y_true = [3, 5, 2.5, 7]\n",
        ",y_pred = [2.5, 5.0, 4.0, 8]\n",
        " Calculate the quantities MSE, MAE, MAPE, RMSE.\n",
        " Explain when we use MAPE?"
      ],
      "metadata": {
        "id": "fsdUdvTUaN6R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate regression model performance\n",
        "using common error metrics:\n",
        "- MAE (Mean Absolute Error)\n",
        "- MSE (Mean Squared Error)\n",
        "- RMSE (Root Mean Squared Error)\n",
        "- MAPE (Mean Absolute Percentage Error)"
      ],
      "metadata": {
        "id": "qwSHmisIdb5Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### üîπ Mean Absolute Percentage Error (MAPE)\n",
        "\n",
        "**Definition:**\n",
        "The **Mean Absolute Percentage Error (MAPE)** measures the average percentage difference between the predicted and the actual values.\n",
        "It is a scale-independent metric that expresses prediction accuracy as a percentage, making it easy to interpret even by non-technical audiences.\n",
        "\n",
        "\n",
        "![Untitled.png](data:image/png;base64,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)\n",
        "\n",
        "where:\n",
        "\n",
        "* ( y_i ): actual (true) value\n",
        "* ( y^_i ): predicted value\n",
        "* ( n ): number of observations\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Interpretation\n",
        "\n",
        "MAPE tells you **how far your predictions deviate from the true values in percentage terms**.\n",
        "For example, a MAPE of **22.73%** means the model‚Äôs predictions are off by about **22.73% on average**.\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Advantages\n",
        "\n",
        "‚úÖ **Intuitive and easy to interpret:**\n",
        "Expressing errors in percentages helps communicate model performance clearly (e.g., ‚Äúthe model has an average error of 22.73%‚Äù).\n",
        "\n",
        "‚úÖ **Scale-independent:**\n",
        "MAPE can be used to compare models across different datasets or units (e.g., sales in dollars vs. energy in kWh).\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Limitations\n",
        "\n",
        "üö´ **Division by zero problem:**\n",
        "If any true value (( y_i = 0 )), MAPE becomes undefined or extremely large.\n",
        "Therefore, it should **not** be used with datasets containing zeros or near-zero values.\n",
        "\n",
        "üö´ **Not suitable for negative targets:**\n",
        "MAPE assumes that all true values are positive.\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ When to Use MAPE\n",
        "\n",
        "| Scenario                                    | Use MAPE? |\n",
        "| ------------------------------------------- | --------- |\n",
        "| All target values are positive              | ‚úÖ Yes     |\n",
        "| You need a percentage-based error metric    | ‚úÖ Yes     |\n",
        "| Dataset contains zeros or very small values | ‚ùå No      |\n",
        "| Dataset contains negative values            | ‚ùå No      |\n",
        "| Comparing models on different scales        | ‚úÖ Yes     |"
      ],
      "metadata": {
        "id": "v_twB0Z4cNmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "\n",
        "y_true = [3, 5, 2.5, 7]\n",
        "y_pred = [2.5, 5.0, 4.0, 8]\n",
        "\n",
        "# Convert lists to NumPy arrays for element-wise operations\n",
        "y_true_np = np.array(y_true)\n",
        "y_pred_np = np.array(y_pred)\n",
        "\n",
        "MAE = metrics.mean_absolute_error(y_true, y_pred)\n",
        "MSE = metrics.mean_squared_error(y_true, y_pred)\n",
        "RMSE = np.sqrt(MSE)\n",
        "MAPE = np.mean(np.abs((y_true_np - y_pred_np) / y_true_np)) * 100\n",
        "print(\"MAE:\", MAE)\n",
        "print(\"MSE:\", MSE)\n",
        "print(\"RMSE:\", RMSE)\n",
        "print(\"MAPE:\", MAPE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AaKLKGvaqNQ",
        "outputId": "68d9231b-f0f6-45b5-d8a0-b6da4ee86f13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.75\n",
            "MSE: 0.875\n",
            "RMSE: 0.9354143466934853\n",
            "MAPE: 22.738095238095234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**EXAMPLE**\n",
        "\n",
        "y_true = [1, 0, 1, 0]\n",
        " , y_pred = [0.9, 0.2, 0.7, 0.1]. Calculate the BCE quantity."
      ],
      "metadata": {
        "id": "2EAAczIfoT2x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definition:\n",
        "The Binary Cross-Entropy (BCE) ‚Äî also known as Log Loss ‚Äî measures the dissimilarity between true binary labels and predicted probabilities in a binary classification problem.\n",
        "It quantifies how close the predicted probability distributions are to the actual class labels.\n",
        "\n",
        "![Untitled.png](data:image/png;base64,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)\n",
        "\n",
        "where:\n",
        "\n",
        "y_i: actual binary label (0 or 1)\n",
        "\n",
        "y^_i: predicted probability for the positive class\n",
        "\n",
        "n: number of samples\n",
        "\n",
        "\n",
        "\n",
        "üîπ Intuition\n",
        "\n",
        "BCE measures how confident your model is about its predictions:\n",
        "\n",
        "A perfect prediction (probability = 1 for true class) gives a loss close to 0.\n",
        "\n",
        "A wrong or uncertain prediction increases the loss significantly.\n",
        "Thus, the goal of training is to minimize BCE, meaning the model‚Äôs predicted probabilities align closely with the true labels.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "üîπ Advantages\n",
        "\n",
        "‚úÖ Works directly with probabilistic outputs, not just class labels.\n",
        "\n",
        "‚úÖ Penalizes overconfident wrong predictions more heavily.\n",
        "\n",
        "‚úÖ The most common loss function for binary classifiers such as logistic regression, neural networks, or CNNs in binary tasks.\n",
        "\n",
        "\n",
        "\n",
        "| Scenario                          | Use BCE?                                     |\n",
        "| --------------------------------- | -------------------------------------------- |\n",
        "| Binary classification problem     | ‚úÖ Yes                                        |\n",
        "| Model outputs probabilities (0‚Äì1) | ‚úÖ Yes                                        |\n",
        "| Multi-class classification        | ‚ùå No (use categorical cross-entropy instead) |\n",
        "| Regression tasks                  | ‚ùå No (use MSE/MAE instead)                   |\n"
      ],
      "metadata": {
        "id": "z2jmkhNepES_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "binary_cross_entropy\n",
        "-----------------------\n",
        "A simple script to calculate Binary Cross-Entropy (BCE)\n",
        "for binary classification tasks.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def binary_cross_entropy(y_true, y_pred):\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.clip(np.array(y_pred), 1e-15, 1 - 1e-15)  # Avoid log(0)\n",
        "    bce = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "    return bce\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    y_true = [1, 0, 1, 0]\n",
        "    y_pred = [0.9, 0.2, 0.7, 0.1]\n",
        "\n",
        "    result = binary_cross_entropy(y_true, y_pred)\n",
        "    print(f\"Binary Cross-Entropy (BCE): {result:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbMWGJ9TcMtS",
        "outputId": "0e4ccf11-f560-4fbb-919b-6acac6b65ffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary Cross-Entropy (BCE): 0.1976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```python\n",
        "y_pred = np.clip(np.array(y_pred), 1e-15, 1 - 1e-15)\n",
        "```\n",
        "\n",
        "**Explanation:**\n",
        "\n",
        "* `np.array(y_pred)` converts the predicted values to a NumPy array.\n",
        "* `np.clip(x, a, b)` limits (or *clips*) all values in `x` to be within the range `[a, b]`.\n",
        "\n",
        "  * Any value smaller than `1e-15` (0.000000000000001) becomes `1e-15`.\n",
        "  * Any value larger than `1 - 1e-15` (0.999999999999999) becomes `1 - 1e-15`.\n",
        "\n",
        "**Why we do this:**\n",
        "When calculating binary cross-entropy (BCE), we use logarithms:\n",
        "\n",
        "log(y_pred)\n",
        "\n",
        "log(1 - y_pred)\n",
        "\n",
        "\n",
        "If `y_pred` is exactly `0` or `1`, then we would have:\n",
        "\n",
        "* `log(0)` ‚Üí equals **-‚àû** (undefined, causes an error)\n",
        "* `log(1)` ‚Üí equals **0**, which is fine, but `log(1 - 1)` again gives `log(0)` if `y_pred = 1`\n",
        "\n",
        "So, to **avoid taking the log of zero**, we slightly ‚Äúpush‚Äù all predictions away from 0 and 1.\n",
        "This ensures the BCE loss remains numerically stable and doesn‚Äôt produce infinite or NaN values.\n",
        "\n",
        "üëâ\n",
        "**This line prevents mathematical errors (like log(0)) and keeps the loss function stable.**\n"
      ],
      "metadata": {
        "id": "czxOdaUntzSw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**EXAMPLE**\n",
        "Calculate the multi-class Cross-Entropy quantity for the results shown.\n",
        "| Sample | y_true | Predicted Probabilities [C1, C2, C3] |\n",
        "| :----: | :----: | :----------------------------------: |\n",
        "|    1   |    1   |            [0.7, 0.2, 0.1]           |\n",
        "|    2   |    2   |            [0.1, 0.6, 0.3]           |\n",
        "|    3   |    3   |            [0.2, 0.3, 0.5]           |\n"
      ],
      "metadata": {
        "id": "BAmIhhKqvTun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is Multi-Class Cross-Entropy (Categorical Cross-Entropy)?\n",
        "\n",
        "Categorical Cross-Entropy (CCE) ‚Äî also called Multi-Class Cross-Entropy ‚Äî is a loss function used in multi-class classification problems where each input sample belongs to one and only one class out of multiple possible classes.\n",
        "\n",
        "It measures how well the predicted probability distribution (from a model, such as a neural network with a Softmax output) matches the true class labels.\n",
        "\n",
        "![Untitled.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "Where:\n",
        "\n",
        "* ( N ): number of samples\n",
        "* ( C ): number of classes\n",
        "* ( y_{i,c} ): true label (1 if sample *i* belongs to class *c*, otherwise 0)\n",
        "* ( p_{i,c} ): predicted probability that sample *i* belongs to class *c*\n",
        "\n",
        "\n",
        "\n",
        "### ‚öôÔ∏è When Do We Use It?\n",
        "\n",
        "Use **Categorical Cross-Entropy** when:\n",
        "\n",
        "* You are solving a **multi-class classification** task (e.g., image classification with 10 classes).\n",
        "* Your model outputs **a probability distribution** (via Softmax) across all classes.\n",
        "* Each input belongs to **only one class** (not multiple).\n",
        "\n",
        "If you have **multi-label classification** (samples can belong to several classes at once), use **Binary Cross-Entropy** instead.\n",
        "\n",
        "\n",
        "### üìä Intuition\n",
        "\n",
        "* The loss is **low** when the model assigns **high probability** to the correct class.\n",
        "* The loss is **high** when the model assigns **low probability** to the correct class.\n",
        "* The goal during training is to **minimize this loss**, which means improving confidence in correct predictions.\n"
      ],
      "metadata": {
        "id": "ScCjrKgvwYwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "def multi_class_cross_entropy(y_true, y_pred):\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # Clip to avoid log(0)\n",
        "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
        "\n",
        "    # Convert 1-based labels to 0-based if necessary\n",
        "    if y_true.min() == 1:\n",
        "        y_true_indexed = y_true - 1\n",
        "    else:\n",
        "        y_true_indexed = y_true\n",
        "\n",
        "    # Select the predicted probability of the true class for each sample\n",
        "    true_class_probs = y_pred[np.arange(len(y_true)), y_true_indexed]\n",
        "\n",
        "    # Compute the mean negative log-likelihood\n",
        "    loss = -np.mean(np.log(true_class_probs))\n",
        "    return loss\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage\n",
        "    y_true = [1, 2, 3]  # true labels (1-based)\n",
        "    y_pred = [\n",
        "        [0.7, 0.2, 0.1],\n",
        "        [0.1, 0.6, 0.3],\n",
        "        [0.2, 0.3, 0.5],\n",
        "    ]\n",
        "\n",
        "    loss_value = multi_class_cross_entropy(y_true, y_pred)\n",
        "    print(f\"Multi-class Cross-Entropy Loss: {loss_value:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh3TlTOs39SL",
        "outputId": "6fa007a2-b439-4f5a-e03e-47faef95c6a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multi-class Cross-Entropy Loss: 0.5202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use One-Hot Encoding :**"
      ],
      "metadata": {
        "id": "h-_pkyM2_snu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def multi_class_cross_entropy_onehot(y_true_onehot, y_pred):\n",
        "\n",
        "    y_true_onehot = np.array(y_true_onehot)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # Clip predictions to avoid log(0)\n",
        "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
        "\n",
        "    # Cross-Entropy: sum over classes, then mean over samples\n",
        "    loss_per_sample = -np.sum(y_true_onehot * np.log(y_pred), axis=1)\n",
        "    loss = np.mean(loss_per_sample)\n",
        "\n",
        "    return loss\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    y_true_onehot = [\n",
        "        [1, 0, 0],\n",
        "        [0, 1, 0],\n",
        "        [0, 0, 1],\n",
        "    ]\n",
        "\n",
        "    y_pred = [\n",
        "        [0.7, 0.2, 0.1],\n",
        "        [0.1, 0.6, 0.3],\n",
        "        [0.2, 0.3, 0.5],\n",
        "    ]\n",
        "\n",
        "    loss_value = multi_class_cross_entropy_onehot(y_true_onehot, y_pred)\n",
        "    print(f\"Multi-class Cross-Entropy Loss (One-Hot): {loss_value:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iieKkt9A7T7a",
        "outputId": "a9cc3f30-f8cf-40f2-bc5d-fea3bde68a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multi-class Cross-Entropy Loss (One-Hot): 0.5202\n"
          ]
        }
      ]
    }
  ]
}